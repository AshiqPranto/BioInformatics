---
title: "GSE140809GeneExpressionAnalysisManual"
author: "Pranto"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

Import count matrix and metadata
```{r message=FALSE, warning=FALSE}
counts <- read.csv("GSE140809_DENV_gene_count_matrix.csv") #import counts data
library(GEOquery)
colData <- getGEO(GEO = "GSE140809",GSEMatrix = TRUE)
colData <- colData[["GSE140809_series_matrix.txt.gz"]]@phenoData@data
View(colData)
write.csv(colData,file = "GSE140809_DENV_gene_ColData_Matrix.csv")
colData <- read.csv("GSE140809_DENV_gene_ColData_Matrix.csv");
```
Check if all the description column value of colData matrix match inorder with the colnames of counts matrix. Then replace the sample name.
```{r}
counts1 <- counts
counts1 <- counts[,-1]
rownames(counts1) <- counts[,"gene_id"]
counts <- counts1
colnames(counts) <- substring(colnames(counts),2)
all(colnames(counts) == colData$description)
colnames(counts) <- rownames(colData)
all(colnames(counts) == rownames(colData))
```
Applying CPM Normalization without any library
```{r}
counts <- as.data.frame(counts)
columnSums <- colSums(counts)
countsNormalized <- counts
for(j in 1:ncol(countsNormalized))
{
  print(j)
  for (i in 1:nrow(countsNormalized)) {
    countsNormalized[i,j] = (counts[i,j]/columnSums[j])*1000000
  }
}
write.csv(countsNormalized,file = "countsNormalizedCPMGSE140809.csv")
countsNormalized <- read.csv("countsNormalizedCPMGSE140809.csv")
countsNormalized <- as.data.frame(countsNormalized)
countsNormalized <- as.matrix(countsNormalized)
```
The above cpmNormalization takes longer time. That's why I calculate that ones and 
store in my directory. If you want to restore the data then following code will help you to do that. It will restore the data, set rownames from firstColumn and remove the first column again and also convert to numeric value for all elements.

Remove genes those have very low expressed values
```{r}
nrow(countsNormalized)
countsNormalized <- countsNormalized[rowSums(countsNormalized)>2,]
nrow(countsNormalized)
```
Extract all genes those are acute
```{r}
acute.colDataIndex <- grepl("acute",colData$title)
acute.colDataIndex
acute.colData <- colData[acute.colDataIndex,]
nrow(acute.colData)
acute.sampleName <- rownames(acute.colData)
acute.sampleName
acute.counts <- countsNormalized[,acute.sampleName]

acute.means <- as.data.frame(rowMeans(acute.counts))
View(acute.means)
```
Extract all genes those are convalescent
```{r}
convalescent.colDataIndex <- grepl("convalescent",colData$title)
convalescent.colData <- colData[convalescent.colDataIndex,]
convalescent.sampleName <- rownames(convalescent.colData)
convalescent.counts <- countsNormalized[,convalescent.sampleName]

convalescent.means <- as.data.frame(rowMeans(convalescent.counts))
View(convalescent.means)
nrow(convalescent.means)
```
Store two mean result in a new dataframe called meanCounts
```{r}
all(rownames(acute.means) == rownames(convalescent.means))
meanCounts <- data.frame(convalescent.means,acute.means)
View(meanCounts)
nrow(meanCounts)
```
Filter Out zero count genes
```{r}
to.remove <- unique(which(meanCounts==0,arr.ind = TRUE)[,1])
#to.remove <- as.data.frame(to.remove)
#to.remove
meanCountsWithoutZero <- meanCounts[-to.remove,]
nrow(meanCountsWithoutZero)
```
Calculate log2FoldChange, #upgenges and #downges
```{r}
log2fc <- log2(meanCountsWithoutZero$rowMeans.acute.counts./meanCountsWithoutZero$rowMeans.convalescent.counts.)
threShold <- 2
log2fc <- as.data.frame(log2fc)
log2fc
upGenes <- sum(log2fc>threShold)
upGenes
downGenes <- sum(log2fc<(-threShold))
downGenes
```
```{r}
library(DESeq2)
View(colData)
dds <- DESeqDataSetFromMatrix(countData = counts,colData = colData,design = ~)
```

